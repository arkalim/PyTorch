{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Creation Notes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/PyTorch/blob/master/Model_Creation_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3BXcOoAr9Ci",
        "colab_type": "text"
      },
      "source": [
        "Today, we are going to see how to use the three main building blocks of PyTorch: Module, Sequential and ModuleList. We are going to start with an example and iteratively we will make it better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN2kJwQOqFXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhoWh6masgqP",
        "colab_type": "text"
      },
      "source": [
        "## Simplest version of a classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjSpw4ujsKCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "37ccb351-6599-4668-e165-8427fb9bc9f4"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n",
        "        self.fc2 = nn.Linear(1024, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = Network(1,10)\n",
        "print(model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvxZHUrms28I",
        "colab_type": "text"
      },
      "source": [
        "If we want to add a layer we have to again write lots of code in the __init__ and in the forward function. Also, if we have some common block that we want to use in another model, e.g. the 3x3 conv + batchnorm + relu, we have to write it again.\n",
        "## Sequential: stack and merge layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tt59aQ-s3xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "56e95dd3-2abd-42ba-a1d6-9dae808e01a2"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self, channel_in, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(channel_in, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "\n",
        "        x = x.view(x.size(dim = 0), -1) # flatten\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = Network(1,10) \n",
        "print(model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv_block1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv_block2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY1XTcC_uDTC",
        "colab_type": "text"
      },
      "source": [
        "Still, conv_block1 and conv_block2 looks almost the same. We could create a function that reteurns a nn.Sequential to even simplify the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Ohb_nTu3aX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3fdd35e1-c827-418d-9974-b7d06a16ec02"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_channel, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # defining the conv blocks as attributes\n",
        "        self.conv_block1 = self.conv_block(in_channel, 32, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv_block2 = self.conv_block(32, 64, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "        \n",
        "    # function that returns conv blocks    \n",
        "    def conv_block(self,in_filters, out_filters, *args, **kwargs):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_filters, out_filters, *args, **kwargs),\n",
        "            nn.BatchNorm2d(out_filters),\n",
        "            nn.ReLU()\n",
        "        )    \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "network_2 = Network(1,10)\n",
        "print(network_2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv_block1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv_block2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2jEzCDLwDvF",
        "colab_type": "text"
      },
      "source": [
        "Still conv_block1 and conv_block2 are almost the same! We can merge them using nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_oeT3TVvh6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "d741091b-ec26-4a2e-f2d7-499e470e7baa"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_channel, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # defining the encoder as a Sequential combination of conv blocks\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.conv_block(in_channel, 32, kernel_size=3, padding=1),\n",
        "            self.conv_block(32, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "        \n",
        "    # function that returns conv blocks    \n",
        "    def conv_block(self,in_filters, out_filters, *args, **kwargs):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_filters, out_filters, *args, **kwargs),\n",
        "            nn.BatchNorm2d(out_filters),\n",
        "            nn.ReLU()\n",
        "        )    \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "network_3 = Network(1,10)\n",
        "print(network_3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (encoder): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujA9QJXqRWUm",
        "colab_type": "text"
      },
      "source": [
        "## ModuleList : when we need to iterate\n",
        "ModuleList allows you to store Module as a list. It can be useful when you need to iterate through layer and store/use some information, like in U-net.\n",
        "\n",
        "The main difference between Sequential is that ModuleList have not a forward method so the inner layers are not connected. Assuming we need each output of each layer in the decoder, we can store it by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvUHhfBsRX5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d8750a47-a2f2-480f-97df-02ca2773175f"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self, sizes):\n",
        "        super().__init__()\n",
        "        # use this form to make a list of layers\n",
        "        self.layers = nn.ModuleList([nn.Linear(filters_in, filters_out) for filters_in, filters_out in zip(sizes, sizes[1:])])\n",
        "        self.trace = []\n",
        "        \n",
        "    def forward(self,x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "            # append the output of each layer to trace\n",
        "            self.trace.append(x)\n",
        "        return x\n",
        "    \n",
        "model = Network([1,16,32,64])    \n",
        "\n",
        "print(model)\n",
        "\n",
        "# feed a random tensor into the model to see the output of each layer\n",
        "out = model(torch.rand((4,1)))\n",
        "\n",
        "[print(x.shape) for x in model.trace]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=1, out_features=16, bias=True)\n",
            "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([4, 16])\n",
            "torch.Size([4, 32])\n",
            "torch.Size([4, 64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7N48tjKU04H",
        "colab_type": "text"
      },
      "source": [
        "## ModuleDict: when we need to choose\n",
        "What if we want to switch to LearkyRelu in our conv_block? We can use ModuleDict to create a dictionary of Module and dynamically switch Module when we want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6krgJct8U2sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ac4c1e7c-c014-4522-f802-24b4345596d0"
      },
      "source": [
        "def conv_block(in_f, out_f, activation='relu', *args, **kwargs):\n",
        "    \n",
        "    activations = nn.ModuleDict([\n",
        "                ['lrelu', nn.LeakyReLU()],\n",
        "                ['relu', nn.ReLU()]\n",
        "    ])\n",
        "    \n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
        "        nn.BatchNorm2d(out_f),\n",
        "        activations[activation]\n",
        "    )\n",
        "\n",
        "print(conv_block(1, 32,'lrelu', kernel_size=3, padding=1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(negative_slope=0.01)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN0xAkToV1uZ",
        "colab_type": "text"
      },
      "source": [
        "## Accessing weights of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpcDIhM_YXZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "152a3f3e-2aed-4ab4-d7c2-f4bc59fb8df7"
      },
      "source": [
        "for name, param in network_2.named_parameters():\n",
        "    print('Name: {}      Shape: {}'.format(name, param.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: conv_block1.0.weight      Shape: torch.Size([32, 1, 3, 3])\n",
            "Name: conv_block1.0.bias      Shape: torch.Size([32])\n",
            "Name: conv_block1.1.weight      Shape: torch.Size([32])\n",
            "Name: conv_block1.1.bias      Shape: torch.Size([32])\n",
            "Name: conv_block2.0.weight      Shape: torch.Size([64, 32, 3, 3])\n",
            "Name: conv_block2.0.bias      Shape: torch.Size([64])\n",
            "Name: conv_block2.1.weight      Shape: torch.Size([64])\n",
            "Name: conv_block2.1.bias      Shape: torch.Size([64])\n",
            "Name: decoder.0.weight      Shape: torch.Size([1024, 25088])\n",
            "Name: decoder.0.bias      Shape: torch.Size([1024])\n",
            "Name: decoder.2.weight      Shape: torch.Size([10, 1024])\n",
            "Name: decoder.2.bias      Shape: torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tee1xM9XYaWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2773
        },
        "outputId": "c45da977-54c9-4450-c3c1-a2e690094cfc"
      },
      "source": [
        "print(network_2.conv_block1[0].weight)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.1813,  0.3016,  0.1065],\n",
            "          [-0.2300,  0.2665,  0.0304],\n",
            "          [-0.0722,  0.0862, -0.1226]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597,  0.2799, -0.2240],\n",
            "          [-0.1560, -0.3205, -0.0806],\n",
            "          [-0.1788,  0.2126, -0.3080]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0028, -0.1531, -0.1594],\n",
            "          [-0.3124, -0.0508,  0.1177],\n",
            "          [-0.1244, -0.0753, -0.1156]]],\n",
            "\n",
            "\n",
            "        [[[-0.2866, -0.1170, -0.0453],\n",
            "          [ 0.2169, -0.2491, -0.2628],\n",
            "          [-0.2521,  0.1010,  0.2865]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1071,  0.0961, -0.0265],\n",
            "          [-0.1603, -0.2720,  0.1919],\n",
            "          [ 0.1646,  0.1213,  0.0539]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2713,  0.1730, -0.1299],\n",
            "          [ 0.2504,  0.2500, -0.2485],\n",
            "          [-0.0630,  0.1732,  0.0749]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3025, -0.0232,  0.0219],\n",
            "          [-0.0894, -0.0069, -0.1024],\n",
            "          [ 0.2313,  0.2644,  0.2640]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0021, -0.2720,  0.1208],\n",
            "          [ 0.2177, -0.0704, -0.1544],\n",
            "          [ 0.0426, -0.2196, -0.0513]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2768,  0.3308,  0.1720],\n",
            "          [ 0.2921,  0.1604, -0.2312],\n",
            "          [-0.1542,  0.0096,  0.0589]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2829, -0.2053, -0.0916],\n",
            "          [ 0.1674, -0.2971,  0.1596],\n",
            "          [ 0.3255,  0.1324, -0.0646]]],\n",
            "\n",
            "\n",
            "        [[[-0.1562,  0.0882, -0.2725],\n",
            "          [-0.0529, -0.2295,  0.1482],\n",
            "          [ 0.3088, -0.0524, -0.1160]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2973, -0.2888,  0.3194],\n",
            "          [ 0.2551, -0.2088,  0.1570],\n",
            "          [ 0.2294, -0.1422, -0.1348]]],\n",
            "\n",
            "\n",
            "        [[[-0.2736,  0.0421,  0.1343],\n",
            "          [-0.0155, -0.3099,  0.1098],\n",
            "          [ 0.2615, -0.1230,  0.1558]]],\n",
            "\n",
            "\n",
            "        [[[-0.0461,  0.2345, -0.2893],\n",
            "          [-0.1854,  0.0444,  0.0449],\n",
            "          [ 0.2450, -0.3199,  0.3320]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2144, -0.0696, -0.2928],\n",
            "          [ 0.2526, -0.0983,  0.2713],\n",
            "          [-0.0958, -0.2628, -0.1442]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1069,  0.2549, -0.1320],\n",
            "          [ 0.1708, -0.2322,  0.1073],\n",
            "          [ 0.1668,  0.1900, -0.3048]]],\n",
            "\n",
            "\n",
            "        [[[-0.3318, -0.0357, -0.0185],\n",
            "          [-0.0480, -0.1334,  0.2556],\n",
            "          [ 0.1782,  0.0688, -0.1626]]],\n",
            "\n",
            "\n",
            "        [[[-0.1951,  0.2900, -0.0488],\n",
            "          [-0.1207,  0.0398, -0.3317],\n",
            "          [ 0.2311,  0.2968, -0.2925]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2160, -0.1274,  0.1740],\n",
            "          [ 0.0213,  0.2628,  0.1121],\n",
            "          [ 0.2669, -0.1115, -0.1444]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0833, -0.2868,  0.0723],\n",
            "          [ 0.0380, -0.3300,  0.1247],\n",
            "          [ 0.0456,  0.2227, -0.0037]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0990, -0.1532, -0.0658],\n",
            "          [-0.3298, -0.1998, -0.1686],\n",
            "          [-0.3139,  0.1312,  0.1888]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1115,  0.0523,  0.0123],\n",
            "          [ 0.1128, -0.1006,  0.0998],\n",
            "          [ 0.1566,  0.1709, -0.2371]]],\n",
            "\n",
            "\n",
            "        [[[-0.0361,  0.0157, -0.3156],\n",
            "          [ 0.0172, -0.0967,  0.1479],\n",
            "          [ 0.1516,  0.1273,  0.2293]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3156,  0.0028, -0.2422],\n",
            "          [ 0.1853, -0.1610,  0.1898],\n",
            "          [-0.2197, -0.0630, -0.0247]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1830,  0.3320, -0.2232],\n",
            "          [ 0.1804, -0.2963,  0.2894],\n",
            "          [-0.0355,  0.1718,  0.3015]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0187, -0.0452,  0.3066],\n",
            "          [-0.2215, -0.3269,  0.0473],\n",
            "          [ 0.1986,  0.2131, -0.0269]]],\n",
            "\n",
            "\n",
            "        [[[-0.2374,  0.0983, -0.2004],\n",
            "          [ 0.0523, -0.1758, -0.3207],\n",
            "          [ 0.3256, -0.0999,  0.2926]]],\n",
            "\n",
            "\n",
            "        [[[-0.2504,  0.1543, -0.1448],\n",
            "          [ 0.1967, -0.1768, -0.0473],\n",
            "          [ 0.1424,  0.0037, -0.0434]]],\n",
            "\n",
            "\n",
            "        [[[-0.1481, -0.0274,  0.3145],\n",
            "          [-0.0728,  0.3095,  0.2630],\n",
            "          [ 0.2988, -0.0305,  0.1415]]],\n",
            "\n",
            "\n",
            "        [[[-0.0399,  0.0537,  0.0096],\n",
            "          [ 0.2731, -0.0842,  0.2024],\n",
            "          [-0.1491, -0.3186,  0.3061]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2679, -0.2063,  0.1864],\n",
            "          [ 0.2004,  0.1150, -0.0106],\n",
            "          [ 0.1121,  0.2610, -0.2950]]],\n",
            "\n",
            "\n",
            "        [[[-0.0027, -0.0370,  0.2938],\n",
            "          [ 0.1065,  0.2055,  0.1124],\n",
            "          [-0.1115,  0.1041, -0.1014]]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHZnylNV49E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4ef3b968-7743-4543-fa2b-fc458b6b21f7"
      },
      "source": [
        "for name, param in network_3.named_parameters():\n",
        "    print('Name: {}      Shape: {}'.format(name, param.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: encoder.0.0.weight      Shape: torch.Size([32, 1, 3, 3])\n",
            "Name: encoder.0.0.bias      Shape: torch.Size([32])\n",
            "Name: encoder.0.1.weight      Shape: torch.Size([32])\n",
            "Name: encoder.0.1.bias      Shape: torch.Size([32])\n",
            "Name: encoder.1.0.weight      Shape: torch.Size([64, 32, 3, 3])\n",
            "Name: encoder.1.0.bias      Shape: torch.Size([64])\n",
            "Name: encoder.1.1.weight      Shape: torch.Size([64])\n",
            "Name: encoder.1.1.bias      Shape: torch.Size([64])\n",
            "Name: decoder.0.weight      Shape: torch.Size([1024, 25088])\n",
            "Name: decoder.0.bias      Shape: torch.Size([1024])\n",
            "Name: decoder.2.weight      Shape: torch.Size([10, 1024])\n",
            "Name: decoder.2.bias      Shape: torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNElPGpKXLpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2773
        },
        "outputId": "d83db3ba-b218-413c-bf88-bc5ab5358491"
      },
      "source": [
        "print(network_3.encoder[0][0].weight)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.2732, -0.2741, -0.0126],\n",
            "          [-0.1148,  0.2462, -0.1302],\n",
            "          [ 0.0691, -0.2845, -0.3233]]],\n",
            "\n",
            "\n",
            "        [[[-0.2175, -0.1577,  0.0981],\n",
            "          [ 0.3065,  0.2226,  0.0250],\n",
            "          [ 0.3090,  0.2913, -0.1763]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3049,  0.1212,  0.2746],\n",
            "          [ 0.2395, -0.1232, -0.2852],\n",
            "          [ 0.0535, -0.2075,  0.2906]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1554, -0.2954, -0.1115],\n",
            "          [-0.1020,  0.1374,  0.2249],\n",
            "          [-0.2360,  0.3282, -0.0927]]],\n",
            "\n",
            "\n",
            "        [[[-0.0089, -0.1333,  0.1938],\n",
            "          [-0.0938, -0.2730,  0.1930],\n",
            "          [-0.2393,  0.0766,  0.1745]]],\n",
            "\n",
            "\n",
            "        [[[-0.3313,  0.3092, -0.0275],\n",
            "          [ 0.2731, -0.1712,  0.1513],\n",
            "          [ 0.0917,  0.2621, -0.1094]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158,  0.1030, -0.1795],\n",
            "          [ 0.2042,  0.0680,  0.0666],\n",
            "          [-0.1753,  0.0203,  0.3320]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2696,  0.0389,  0.1725],\n",
            "          [ 0.0950,  0.1126, -0.1503],\n",
            "          [-0.0016,  0.2869, -0.0130]]],\n",
            "\n",
            "\n",
            "        [[[-0.2750,  0.1944,  0.1212],\n",
            "          [ 0.0458,  0.2898, -0.1939],\n",
            "          [-0.0768,  0.2444, -0.0530]]],\n",
            "\n",
            "\n",
            "        [[[-0.1866, -0.3313, -0.1378],\n",
            "          [-0.1021,  0.0254,  0.1632],\n",
            "          [-0.3157,  0.1598,  0.0453]]],\n",
            "\n",
            "\n",
            "        [[[-0.0495,  0.1359, -0.1580],\n",
            "          [-0.1581, -0.0927, -0.2678],\n",
            "          [-0.3267,  0.2141,  0.1191]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0165, -0.0019,  0.1540],\n",
            "          [-0.1562, -0.0897,  0.2221],\n",
            "          [-0.1455,  0.3036,  0.0670]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009,  0.0266,  0.1410],\n",
            "          [-0.0611, -0.0196, -0.3280],\n",
            "          [ 0.1825,  0.0282,  0.0124]]],\n",
            "\n",
            "\n",
            "        [[[-0.1270, -0.1079, -0.0929],\n",
            "          [ 0.1221, -0.3136,  0.1378],\n",
            "          [-0.1219, -0.2015, -0.2425]]],\n",
            "\n",
            "\n",
            "        [[[-0.2028, -0.1192, -0.2740],\n",
            "          [ 0.2427,  0.1739,  0.2262],\n",
            "          [-0.2703,  0.0125,  0.1363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2623, -0.0317,  0.1449],\n",
            "          [ 0.2423,  0.0432, -0.0279],\n",
            "          [ 0.0179,  0.2024, -0.3040]]],\n",
            "\n",
            "\n",
            "        [[[-0.2887, -0.3053,  0.0106],\n",
            "          [ 0.2625,  0.2575, -0.2911],\n",
            "          [-0.1995,  0.2446, -0.1040]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1170,  0.0078, -0.1426],\n",
            "          [-0.1692,  0.0333, -0.2316],\n",
            "          [ 0.0352, -0.0354,  0.1122]]],\n",
            "\n",
            "\n",
            "        [[[-0.1811,  0.1446, -0.3248],\n",
            "          [-0.1008,  0.1540,  0.0904],\n",
            "          [-0.2896,  0.1644,  0.0518]]],\n",
            "\n",
            "\n",
            "        [[[-0.2920, -0.0673, -0.0844],\n",
            "          [-0.0539,  0.2438, -0.2428],\n",
            "          [-0.3127,  0.0780,  0.1776]]],\n",
            "\n",
            "\n",
            "        [[[-0.3015,  0.1396,  0.1812],\n",
            "          [ 0.1334, -0.0011,  0.0794],\n",
            "          [ 0.2314,  0.2733,  0.2983]]],\n",
            "\n",
            "\n",
            "        [[[-0.1290, -0.2846,  0.0737],\n",
            "          [ 0.2159,  0.0331,  0.3030],\n",
            "          [ 0.3178,  0.0615,  0.0531]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.0182,  0.1108],\n",
            "          [-0.0312,  0.2701,  0.2594],\n",
            "          [-0.2153,  0.0007, -0.2782]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0090,  0.0686],\n",
            "          [-0.2906,  0.1724, -0.0225],\n",
            "          [ 0.0759, -0.2999, -0.1299]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1958,  0.2042,  0.2332],\n",
            "          [-0.2653, -0.3145, -0.2653],\n",
            "          [ 0.2240,  0.1997,  0.1940]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2084, -0.1716, -0.0804],\n",
            "          [ 0.1346, -0.1338, -0.0376],\n",
            "          [ 0.3156, -0.3233,  0.1598]]],\n",
            "\n",
            "\n",
            "        [[[-0.1757, -0.1332,  0.2589],\n",
            "          [ 0.1011,  0.1409,  0.1364],\n",
            "          [ 0.0256,  0.2023, -0.0206]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0477, -0.1763, -0.1423],\n",
            "          [ 0.3041,  0.0538,  0.1797],\n",
            "          [-0.0088, -0.2730,  0.1674]]],\n",
            "\n",
            "\n",
            "        [[[-0.1366, -0.1194, -0.1056],\n",
            "          [-0.0408, -0.0557,  0.2005],\n",
            "          [ 0.0206, -0.1444,  0.0248]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2242, -0.1528,  0.1876],\n",
            "          [-0.0810, -0.0120,  0.2979],\n",
            "          [ 0.3275,  0.2600,  0.1237]]],\n",
            "\n",
            "\n",
            "        [[[-0.1469,  0.2384, -0.0145],\n",
            "          [-0.0069, -0.0436, -0.0754],\n",
            "          [ 0.2786,  0.3033, -0.2273]]],\n",
            "\n",
            "\n",
            "        [[[-0.3205,  0.1105, -0.1520],\n",
            "          [ 0.0084, -0.1803, -0.3309],\n",
            "          [-0.0425,  0.1754, -0.0321]]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl1UhJzMZ3j_",
        "colab_type": "text"
      },
      "source": [
        "## Accessing weights of a specific block or layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6rL2odnZ1yG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXxGylnGZSh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "44e7f17f-fadf-4f3d-c796-3f2692b8bd6a"
      },
      "source": [
        "for name, param in network_3.encoder.named_parameters():\n",
        "    print('Name: {}      Shape: {}'.format(name, param.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: 0.0.weight      Shape: torch.Size([32, 1, 3, 3])\n",
            "Name: 0.0.bias      Shape: torch.Size([32])\n",
            "Name: 0.1.weight      Shape: torch.Size([32])\n",
            "Name: 0.1.bias      Shape: torch.Size([32])\n",
            "Name: 1.0.weight      Shape: torch.Size([64, 32, 3, 3])\n",
            "Name: 1.0.bias      Shape: torch.Size([64])\n",
            "Name: 1.1.weight      Shape: torch.Size([64])\n",
            "Name: 1.1.bias      Shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek57yRhBcAus",
        "colab_type": "text"
      },
      "source": [
        "## Adding layers to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crMD-7xrcASG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5ef6d7f6-4dde-411c-9aa1-19ef1ae92550"
      },
      "source": [
        "# adding a layer named 'new_layer' to encoder[0] block\n",
        "network_3.encoder[0].new_layer = nn.Linear(12,13)\n",
        "\n",
        "print(network_3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (encoder): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (new_layer): Linear(in_features=12, out_features=13, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-5lST8HiQQt",
        "colab_type": "text"
      },
      "source": [
        "## Unfreezing selected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTC-IUFsiSne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(1, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 4)\n",
        "        self.fc4 = nn.Linear(4, 2)\n",
        "        self.fc5 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "net = Net()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpghJz6xkefn",
        "colab_type": "text"
      },
      "source": [
        "### Find different components of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjwqHxgVjcQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8f37c99f-7a89-4fc5-ddb8-8a865f440193"
      },
      "source": [
        "for name, child in net.named_children():\n",
        "    print(name)  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1\n",
            "fc2\n",
            "fc3\n",
            "fc4\n",
            "fc5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p6pDyQYkbL-",
        "colab_type": "text"
      },
      "source": [
        "### Freeze selected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wfX-hDkkA99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c6d1462d-33e2-40b0-d36e-94e1b7129a21"
      },
      "source": [
        "for name, child in net.named_children():\n",
        "    \n",
        "    if name in ['fc4', 'fc5']:\n",
        "        print(name + ' is unfrozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        print(name + ' is frozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1 is frozen\n",
            "fc2 is frozen\n",
            "fc3 is frozen\n",
            "fc4 is unfrozen\n",
            "fc5 is unfrozen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRSR6WXynZH8",
        "colab_type": "text"
      },
      "source": [
        "# Different ways to define Sequential Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0EEuwPGnYcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH15MhebnyBk",
        "colab_type": "text"
      },
      "source": [
        "### Method 1: Without mentioning layer names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfzYZHQYnw6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9bcb701f-8c9b-4913-d36d-54c1039ae7a0"
      },
      "source": [
        "model_Seq1 = nn.Sequential(\n",
        "          nn.Conv2d(1,20,5),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(20,64,5),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "print(model_Seq1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (3): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4NH1_NXoB8q",
        "colab_type": "text"
      },
      "source": [
        "Layers are numbered sequentially by default\n",
        "### Method 2: Mention layer names  using OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiePCkwFoEjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cebdd16f-b7a7-466f-b8da-78cadb86eb2c"
      },
      "source": [
        "# An OrderedDict is a dictionary subclass that remembers the order that keys were first inserted. \n",
        "# The only difference between dict() and OrderedDict() is that:\n",
        "\n",
        "# OrderedDict preserves the order in which the keys are inserted. \n",
        "# A regular dict doesn’t track the insertion order, \n",
        "# and iterating it gives the values in an arbitrary order. \n",
        "# By contrast, the order the items are inserted is remembered by OrderedDict.\n",
        "\n",
        "model_Seq2 = nn.Sequential(OrderedDict([\n",
        "          ('conv1', nn.Conv2d(1,20,5)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('conv2', nn.Conv2d(20,64,5)),\n",
        "          ('relu2', nn.ReLU())\n",
        "        ]))\n",
        "\n",
        "print(model_Seq2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmO7Fqyvop8S",
        "colab_type": "text"
      },
      "source": [
        "### Method 3: Using a list of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkW-e2COopn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a8c232f8-7a0a-4e99-fe31-b0ae66a7a525"
      },
      "source": [
        "layers = []\n",
        "layers.append(nn.Linear(3, 4))\n",
        "layers.append(nn.Sigmoid())\n",
        "layers.append(nn.Linear(4, 1))\n",
        "layers.append(nn.Sigmoid())\n",
        "\n",
        "model_Seq3 = nn.Sequential(*layers)\n",
        "\n",
        "print(model_Seq3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9zqXk8Yp2-X",
        "colab_type": "text"
      },
      "source": [
        "In this case also, layers are numbered by default\n",
        "### Method 4: Using class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4eIfTJnp7WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "92621cfe-1989-43ca-d65a-451ed1038f9f"
      },
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.conv = torch.nn.Sequential()\n",
        "        self.conv.add_module(\"conv_1\", torch.nn.Conv2d(1, 10, kernel_size=5))\n",
        "        self.conv.add_module(\"maxpool_1\", torch.nn.MaxPool2d(kernel_size=2))\n",
        "        self.conv.add_module(\"relu_1\", torch.nn.ReLU())\n",
        "        self.conv.add_module(\"conv_2\", torch.nn.Conv2d(10, 20, kernel_size=5))\n",
        "        self.conv.add_module(\"dropout_2\", torch.nn.Dropout(p=0.2))\n",
        "        \n",
        "model_Seq4 = ConvNet()\n",
        "\n",
        "print(model_Seq4)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv): Sequential(\n",
            "    (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (relu_1): ReLU()\n",
            "    (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (dropout_2): Dropout(p=0.2)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UKd25UrOQm",
        "colab_type": "text"
      },
      "source": [
        "## Adding, Accessing and Replacing layers in Sequential Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP6nnT5trViF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d8c026fc-ff1d-40c4-b897-99728003de61"
      },
      "source": [
        "# Accessing the layers\n",
        "print(model_Seq1[0])\n",
        "print(model_Seq2.conv1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elsU6j1nsUsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "0eba9d14-c943-462f-a146-bebdf9ab91f1"
      },
      "source": [
        "# replacing the layers\n",
        "model_Seq1[0] = nn.Conv2d(1,50,7,2)\n",
        "model_Seq2.conv1 = nn.Conv2d(1,50,7,2)\n",
        "\n",
        "print(model_Seq1)\n",
        "print(model_Seq2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (3): ReLU()\n",
            ")\n",
            "Sequential(\n",
            "  (conv1): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seOpbfsZsZfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "afb4f2b6-8cab-487d-deba-4758c16cfd4a"
      },
      "source": [
        "# Adding layers\n",
        "model_Seq1 = nn.Sequential(model_Seq1, torch.nn.Linear(2048,365))\n",
        "model_Seq2.add_module('conv3', nn.Conv2d(64, 64, 5))\n",
        "\n",
        "print(model_Seq1)\n",
        "print(model_Seq2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (1): Linear(in_features=2048, out_features=365, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (conv1): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSog068Rs6eS",
        "colab_type": "text"
      },
      "source": [
        "## Adding layers to a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-xbfX8js8Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2791
        },
        "outputId": "122e8819-9204-4d41-f800-24d7a163cb49"
      },
      "source": [
        "# Pretrained Model\n",
        "vgg = models.vgg16(pretrained = True)\n",
        "print(\"Pretrained Model\")\n",
        "print(vgg)\n",
        "\n",
        "# Adding on top of the model\n",
        "print(\"\\n Adding on top of the model\")\n",
        "on_top = nn.Sequential(vgg, net)\n",
        "print(on_top)\n",
        "\n",
        "# take care of the shapes when adding inbetween\n",
        "print(\"\\n Adding in between the model\")\n",
        "in_between = nn.Sequential(vgg.features[:5] , net , vgg.features[5:] , vgg.avgpool , vgg.classifier)\n",
        "print(in_between)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 553433881/553433881 [00:39<00:00, 14070257.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pretrained Model\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            " Adding on top of the model\n",
            "Sequential(\n",
            "  (0): Net(\n",
            "    (fc1): Linear(in_features=1, out_features=16, bias=True)\n",
            "    (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (fc3): Linear(in_features=8, out_features=4, bias=True)\n",
            "    (fc4): Linear(in_features=4, out_features=2, bias=True)\n",
            "    (fc5): Linear(in_features=2, out_features=1, bias=True)\n",
            "  )\n",
            "  (1): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (18): ReLU(inplace)\n",
            "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace)\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (25): ReLU(inplace)\n",
            "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (27): ReLU(inplace)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace)\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace)\n",
            "      (2): Dropout(p=0.5)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace)\n",
            "      (5): Dropout(p=0.5)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            " Adding in between the model\n",
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (1): Net(\n",
            "    (fc1): Linear(in_features=1, out_features=16, bias=True)\n",
            "    (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (fc3): Linear(in_features=8, out_features=4, bias=True)\n",
            "    (fc4): Linear(in_features=4, out_features=2, bias=True)\n",
            "    (fc5): Linear(in_features=2, out_features=1, bias=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (3): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (4): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdXeAg8n189V",
        "colab_type": "text"
      },
      "source": [
        "# Replacing layers of a pretrained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9AyTylT198n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD6RxGNZ5Knc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bc19d59-b059-41ac-9840-4aa45c33c72e"
      },
      "source": [
        "# select a particular layer to replace\n",
        "layers = list(vgg16.children())\n",
        "print('Last Layer',layers[2][-1])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last Layer Linear(in_features=4096, out_features=1000, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkPTVaI35Hxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "73ecf8a7-8acb-4eb3-befb-80feb3003fa8"
      },
      "source": [
        "# replace the selected layer\n",
        "layers[2][-1] = nn.Linear(4096, 10, bias = True)\n",
        "\n",
        "# create a new model using the list\n",
        "new_model = nn.Sequential(*layers)\n",
        "\n",
        "# freeze the pretrained model \n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "for param in new_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# unfreeze the last layer    \n",
        "for param in new_model[2][-1].parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "print(new_model)    \n",
        "\n",
        "# print trainable parameters\n",
        "print('Trainable Parameters: \\n')\n",
        "for name, param in new_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print (name, param.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Trainable Parameters: \n",
            "\n",
            "2.6.weight torch.Size([10, 4096])\n",
            "2.6.bias torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lleky9sZ9Pgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "0c288736-2c7c-4b7b-a1a9-462d9bbfb5da"
      },
      "source": [
        "# Another method\n",
        "\n",
        "model = models.vgg16(True)\n",
        "\n",
        "new_model = torch.nn.Sequential(*(list(model.children())))\n",
        "new_model[2][-1] = nn.Linear(4096, 10, bias = True)\n",
        "\n",
        "# freeze the pretrained model \n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "for param in new_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# unfreeze the last layer    \n",
        "for param in new_model[2][-1].parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "print(new_model)    \n",
        "\n",
        "# print trainable parameters\n",
        "print('Trainable Parameters: \\n')\n",
        "for name, param in new_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print (name, param.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Trainable Parameters: \n",
            "\n",
            "2.6.weight torch.Size([10, 4096])\n",
            "2.6.bias torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}