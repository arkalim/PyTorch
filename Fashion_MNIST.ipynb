{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/PyTorch/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H542u2hW1ABK",
        "colab_type": "code",
        "outputId": "4acfea1c-ebd4-41a6-a534-308f5e715416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRkiXtrFg3m",
        "colab_type": "text"
      },
      "source": [
        "## Define the transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yy8_0feb_W",
        "colab_type": "code",
        "outputId": "c0e83aff-6db4-4a6a-a77c-717a810979c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Define transforms for data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/26421880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 67678908.28it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 416243.28it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 17398902.03it/s]                             \n",
            "8192it [00:00, 152119.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2PRsgx5FavB",
        "colab_type": "text"
      },
      "source": [
        "## Create data loaders to shuffle and create batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KImB-m0F9fHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBoQlcxMmf9",
        "colab_type": "code",
        "outputId": "0ea0c54d-4c34-4aa0-85c2-2cb1f3e51252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print('No. of train images: {}'.format(len(trainset)))\n",
        "print('No. of test images: {}'.format(len(testset)))\n",
        "\n",
        "print('No. of train batches: {}'.format(len(trainloader)))\n",
        "print('No. of test batches: {}'.format(len(testloader)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of train images: 60000\n",
            "No. of test images: 10000\n",
            "No. of train batches: 60\n",
            "No. of test batches: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI_ezXwZFnlu",
        "colab_type": "text"
      },
      "source": [
        "## Create the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKrb6kuhTVd",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "d5077f1f-b8f7-4663-a428-daa3182b4cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(12 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.reshape(-1, 12 * 4 * 4)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# create an instance of the Network    \n",
        "network = Network()\n",
        "\n",
        "# move the network object to GPU\n",
        "network.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6G5NNr4adAl",
        "colab_type": "text"
      },
      "source": [
        "## Function to find the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hY2THcoacfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_acc(pred, label):\n",
        "    correct = pred.argmax(dim = 1).eq(label)\n",
        "    accuracy = correct.to(torch.float32).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzJUuCTJP9T",
        "colab_type": "text"
      },
      "source": [
        "## Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAYa0SiytT-T",
        "colab_type": "code",
        "outputId": "9076cbc7-5555-4ff8-9248-07171e556b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "# loss defined using torch.nn\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# note the starting time to find the total time elapsed\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    \n",
        "    loss_train = 0\n",
        "    loss_valid = 0\n",
        "    acc_train = 0\n",
        "    acc_valid = 0\n",
        "    \n",
        "    for step in range(len(trainloader)):\n",
        "\n",
        "        images , labels = next(iter(trainloader))\n",
        "        \n",
        "        # move the images and labels to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        pred = network(images)\n",
        "        \n",
        "        # clear all the gradients before calculating them\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # find the loss for the current step\n",
        "        loss_train_step = loss(pred , labels)\n",
        "        \n",
        "        # find accuracy\n",
        "        acc_train_step = find_acc(pred, labels)\n",
        "        \n",
        "        # calculate the gradients\n",
        "        loss_train_step.backward()\n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_train += loss_train_step.item()\n",
        "\n",
        "        acc_train += acc_train_step        \n",
        "        \n",
        "    for step in range(len(testloader)):\n",
        "\n",
        "        images , labels = next(iter(testloader))\n",
        "        \n",
        "        # move the images and labels to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        pred = network(images)\n",
        "        \n",
        "        # clear all the gradients before calculating them\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # find the loss for the current step\n",
        "        loss_valid_step = loss(pred , labels)\n",
        "        \n",
        "        # find accuracy\n",
        "        acc_valid_step = find_acc(pred, labels)\n",
        "      \n",
        "        loss_valid += loss_valid_step.item()\n",
        "    \n",
        "        acc_valid += acc_valid_step\n",
        "    \n",
        "    loss_train /= len(trainloader)\n",
        "    loss_valid /= len(testloader)\n",
        "   \n",
        "    acc_train /= len(trainloader)\n",
        "    acc_valid /= len(testloader)\n",
        "    \n",
        "    print('Epoch: {}  Train Loss: {}  Train Acc: {}  Valid Loss: {}  Valid Acc: {}'.format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n",
        "    \n",
        "# find the time at the end of training    \n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "print(\"Total time taken : {}\".format(total_time))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  Train Loss: 2.3002537727355956  Train Acc: 0.11453333894411723  Valid Loss: 2.29201340675354  Valid Acc: 0.11999999731779099\n",
            "Epoch: 2  Train Loss: 2.1909592787424725  Train Acc: 0.3203333499530951  Valid Loss: 1.6700690984725952  Valid Acc: 0.5\n",
            "Epoch: 3  Train Loss: 1.0660977333784103  Train Acc: 0.5928500294685364  Valid Loss: 0.8286855816841125  Valid Acc: 0.6499999761581421\n",
            "Epoch: 4  Train Loss: 0.8608739833037059  Train Acc: 0.6635000288486481  Valid Loss: 0.7773889899253845  Valid Acc: 0.6899999976158142\n",
            "Epoch: 5  Train Loss: 0.7294968138138453  Train Acc: 0.7178833693265915  Valid Loss: 0.6904471516609192  Valid Acc: 0.7199999690055847\n",
            "Epoch: 6  Train Loss: 0.6486187567313512  Train Acc: 0.7522000342607498  Valid Loss: 0.6682687997817993  Valid Acc: 0.7199999690055847\n",
            "Epoch: 7  Train Loss: 0.61022962530454  Train Acc: 0.7698833684126536  Valid Loss: 0.6431833505630493  Valid Acc: 0.7199999690055847\n",
            "Epoch: 8  Train Loss: 0.5745217581590016  Train Acc: 0.781450034181277  Valid Loss: 0.6014862060546875  Valid Acc: 0.7599999904632568\n",
            "Epoch: 9  Train Loss: 0.5529316167036692  Train Acc: 0.7920500377813975  Valid Loss: 0.5914517045021057  Valid Acc: 0.7299999594688416\n",
            "Epoch: 10  Train Loss: 0.52626810024182  Train Acc: 0.8039333721001943  Valid Loss: 0.5970454812049866  Valid Acc: 0.75\n",
            "Total time taken : 353.1590087413788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UwiH2kloZ0O",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA9pgZJBAeH9",
        "colab_type": "code",
        "outputId": "d3e8f686-3fb3-45de-a60b-9226e907909c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def test_model(model):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    num_correct = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    # turning off backprop and gradient calculation.\n",
        "    # this improves performance \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in testloader:\n",
        "\n",
        "            images, labels = batch\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            total_images = len(testset)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            num_correct_batch = pred.argmax(dim = 1).eq(labels).sum().item()\n",
        "\n",
        "            accuracy_batch = pred.argmax(dim = 1).eq(labels).float().mean().item()\n",
        "\n",
        "            num_correct += num_correct_batch\n",
        "            accuracy += accuracy_batch\n",
        "\n",
        "        accuracy /= len(testloader)\n",
        "\n",
        "    print('Total number of test images: {}'.format(total_images))\n",
        "    print('Total number of correct predictions: {}'.format(num_correct))\n",
        "    print('Accuracy: {}'.format(accuracy * 100))\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Elapsed Time : {}\".format(end_time - start_time))\n",
        "    \n",
        "# test the trained network    \n",
        "test_model(network)    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 8003\n",
            "Accuracy: 80.0299978852272\n",
            "Elapsed Time : 0.8791663646697998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRf48X-s_bi",
        "colab_type": "text"
      },
      "source": [
        "## Save and Restore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFkRoyVqhtQD",
        "colab_type": "text"
      },
      "source": [
        "### Save and Load Model's Parameters\n",
        "#### Saving the model's state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5B43LyIixJ_S",
        "colab": {}
      },
      "source": [
        "path = 'network_weights.pth'\n",
        "\n",
        "# Save the parameters\n",
        "torch.save(network.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSb9qaf9oTRH",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the model's state_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lph-8B0oIYw",
        "colab_type": "code",
        "outputId": "2bbf225d-58ca-4ce2-c964-d33c310a2785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# create a new model object \n",
        "new_network = Network()\n",
        "\n",
        "# move the network to GPU\n",
        "new_network.to(device)\n",
        "\n",
        "# load the network's parameters\n",
        "new_network.load_state_dict(torch.load(path))\n",
        "\n",
        "# set the network into evaluate mode\n",
        "new_network.eval()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OElnCu1ZxpNb",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mf927G1cJA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8b420030-0eea-4d22-e424-cfcb3a108653"
      },
      "source": [
        "test_model(new_network)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 8003\n",
            "Accuracy: 80.0299978852272\n",
            "Elapsed Time : 0.9047195911407471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSOVhjAxTFr",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Loading entire Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2B29orBogDu",
        "colab_type": "code",
        "outputId": "9e5d491c-528f-4063-b32b-11e780f0d062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "path = 'full_network.pth'\n",
        "\n",
        "# save the model\n",
        "torch.save(network, path)\n",
        "\n",
        "# load the model\n",
        "new_model = torch.load(path)\n",
        "new_model.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Network. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2Ap96nyj4D",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqd8k1-ghIXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4698595a-e2ad-4f27-dedd-1616d352ce79"
      },
      "source": [
        "test_model(new_model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 8003\n",
            "Accuracy: 80.0299978852272\n",
            "Elapsed Time : 0.8959379196166992\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}