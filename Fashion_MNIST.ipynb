{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/PyTorch/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H542u2hW1ABK",
        "colab_type": "code",
        "outputId": "ba471897-968e-4a85-e933-f65b6f618bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRkiXtrFg3m",
        "colab_type": "text"
      },
      "source": [
        "## Define the transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yy8_0feb_W",
        "colab_type": "code",
        "outputId": "ec0557e3-d5ef-4dd5-da6d-ce833ecfb3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Define transforms for data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:06, 3823445.16it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 95432.05it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4139558.50it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 31945.07it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2PRsgx5FavB",
        "colab_type": "text"
      },
      "source": [
        "## Create data loaders to shuffle and create batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KImB-m0F9fHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBoQlcxMmf9",
        "colab_type": "code",
        "outputId": "648574db-14ed-4a2c-e636-4ec6dcfd3e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print('No. of train images: {}'.format(len(trainset)))\n",
        "print('No. of test images: {}'.format(len(testset)))\n",
        "\n",
        "print('No. of train batches: {}'.format(len(trainloader)))\n",
        "print('No. of test batches: {}'.format(len(testloader)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of train images: 60000\n",
            "No. of test images: 10000\n",
            "No. of train batches: 60\n",
            "No. of test batches: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI_ezXwZFnlu",
        "colab_type": "text"
      },
      "source": [
        "## Create the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKrb6kuhTVd",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "70b95072-7fe3-42e8-c750-97d07a6740e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(12 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.reshape(-1, 12 * 4 * 4)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# create an instance of the Network    \n",
        "network = Network()\n",
        "\n",
        "# move the network object to GPU\n",
        "network.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6G5NNr4adAl",
        "colab_type": "text"
      },
      "source": [
        "## Function to find the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hY2THcoacfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_acc(pred, label):\n",
        "    correct = pred.argmax(dim = 1).eq(label)\n",
        "    accuracy = correct.to(torch.float32).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzJUuCTJP9T",
        "colab_type": "text"
      },
      "source": [
        "## Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAYa0SiytT-T",
        "colab_type": "code",
        "outputId": "3a5834d4-0ee4-4216-b833-6d209cd367b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "# loss defined using torch.nn\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# note the starting time to find the total time elapsed\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    \n",
        "    loss_train = 0\n",
        "    loss_valid = 0\n",
        "    acc_train = 0\n",
        "    acc_valid = 0\n",
        "    \n",
        "    # set the network into train mode\n",
        "    network.train()\n",
        "    \n",
        "    for step in range(len(trainloader)):\n",
        "\n",
        "        images , labels = next(iter(trainloader))\n",
        "        \n",
        "        # move the images and labels to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        pred = network(images)\n",
        "        \n",
        "        # clear all the gradients before calculating them\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # find the loss for the current step\n",
        "        loss_train_step = loss(pred , labels)\n",
        "        \n",
        "        # find accuracy\n",
        "        acc_train_step = find_acc(pred, labels)\n",
        "        \n",
        "        # calculate the gradients\n",
        "        loss_train_step.backward()\n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_train += loss_train_step.item()\n",
        "\n",
        "        acc_train += acc_train_step  \n",
        "        \n",
        "    network.eval()    \n",
        "        \n",
        "    for step in range(len(testloader)):\n",
        "\n",
        "        images , labels = next(iter(testloader))\n",
        "        \n",
        "        # move the images and labels to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        pred = network(images)\n",
        "        \n",
        "        # clear all the gradients before calculating them\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # find the loss for the current step\n",
        "        loss_valid_step = loss(pred , labels)\n",
        "        \n",
        "        # find accuracy\n",
        "        acc_valid_step = find_acc(pred, labels)\n",
        "      \n",
        "        loss_valid += loss_valid_step.item()\n",
        "    \n",
        "        acc_valid += acc_valid_step\n",
        "    \n",
        "    loss_train /= len(trainloader)\n",
        "    loss_valid /= len(testloader)\n",
        "   \n",
        "    acc_train /= len(trainloader)\n",
        "    acc_valid /= len(testloader)\n",
        "    \n",
        "    print('Epoch: {}  Train Loss: {}  Train Acc: {}  Valid Loss: {}  Valid Acc: {}'.format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n",
        "    \n",
        "# find the time at the end of training    \n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "print(\"Total time taken : {}\".format(total_time))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  Train Loss: 2.3032644152641297  Train Acc: 0.09945000434915224  Valid Loss: 2.2960023880004883  Valid Acc: 0.09999999403953552\n",
            "Epoch: 2  Train Loss: 2.293939208984375  Train Acc: 0.10143333797653516  Valid Loss: 2.282881259918213  Valid Acc: 0.09999999403953552\n",
            "Epoch: 3  Train Loss: 2.1478913048903148  Train Acc: 0.25403334411482015  Valid Loss: 1.5311754941940308  Valid Acc: 0.44999998807907104\n",
            "Epoch: 4  Train Loss: 1.0353164047002792  Train Acc: 0.608083360393842  Valid Loss: 0.8027231097221375  Valid Acc: 0.6699999570846558\n",
            "Epoch: 5  Train Loss: 0.7841018269459407  Train Acc: 0.7015333662430445  Valid Loss: 0.7975581884384155  Valid Acc: 0.6499999761581421\n",
            "Epoch: 6  Train Loss: 0.6961853017409643  Train Acc: 0.7313667019208272  Valid Loss: 0.7145153284072876  Valid Acc: 0.7099999785423279\n",
            "Epoch: 7  Train Loss: 0.6426092356443405  Train Acc: 0.755000035961469  Valid Loss: 0.7043855786323547  Valid Acc: 0.7099999785423279\n",
            "Epoch: 8  Train Loss: 0.6058665176232656  Train Acc: 0.768666700522105  Valid Loss: 0.6846460700035095  Valid Acc: 0.75\n",
            "Epoch: 9  Train Loss: 0.5793430666128795  Train Acc: 0.7781833698352177  Valid Loss: 0.6035508513450623  Valid Acc: 0.75\n",
            "Epoch: 10  Train Loss: 0.5506190702319145  Train Acc: 0.7937500377496084  Valid Loss: 0.5720587372779846  Valid Acc: 0.7599999904632568\n",
            "Total time taken : 340.07138109207153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UwiH2kloZ0O",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA9pgZJBAeH9",
        "colab_type": "code",
        "outputId": "18f22d4a-f8ca-4867-a975-b0fa8829744b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def test_model(model):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    num_correct = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    # turning off backprop and gradient calculation.\n",
        "    # this improves performance \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in testloader:\n",
        "\n",
        "            images, labels = batch\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            total_images = len(testset)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            num_correct_batch = pred.argmax(dim = 1).eq(labels).sum().item()\n",
        "\n",
        "            accuracy_batch = pred.argmax(dim = 1).eq(labels).float().mean().item()\n",
        "\n",
        "            num_correct += num_correct_batch\n",
        "            accuracy += accuracy_batch\n",
        "\n",
        "        accuracy /= len(testloader)\n",
        "\n",
        "    print('Total number of test images: {}'.format(total_images))\n",
        "    print('Total number of correct predictions: {}'.format(num_correct))\n",
        "    print('Accuracy: {}'.format(accuracy * 100))\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Elapsed Time : {}\".format(end_time - start_time))\n",
        "    \n",
        "# test the trained network    \n",
        "test_model(network)    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 7884\n",
            "Accuracy: 78.83999824523926\n",
            "Elapsed Time : 0.8637130260467529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRf48X-s_bi",
        "colab_type": "text"
      },
      "source": [
        "## Save and Restore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFkRoyVqhtQD",
        "colab_type": "text"
      },
      "source": [
        "### Save and Load Model's Parameters\n",
        "#### Saving the model's state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5B43LyIixJ_S",
        "colab": {}
      },
      "source": [
        "path = 'network_weights.pth'\n",
        "\n",
        "# Save the parameters\n",
        "torch.save(network.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSb9qaf9oTRH",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the model's state_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lph-8B0oIYw",
        "colab_type": "code",
        "outputId": "099be784-0f9c-48ab-d122-4bf354fec06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# create a new model object \n",
        "new_network = Network()\n",
        "\n",
        "# move the network to GPU\n",
        "new_network.to(device)\n",
        "\n",
        "# load the network's parameters\n",
        "new_network.load_state_dict(torch.load(path))\n",
        "\n",
        "# set the network into evaluate mode\n",
        "new_network.eval()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OElnCu1ZxpNb",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mf927G1cJA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d635f9be-11da-410e-c0ba-6b9cee472a50"
      },
      "source": [
        "test_model(new_network)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 7884\n",
            "Accuracy: 78.83999824523926\n",
            "Elapsed Time : 0.857184648513794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSOVhjAxTFr",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Loading entire Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2B29orBogDu",
        "colab_type": "code",
        "outputId": "0ec495bb-1e75-4c8b-f0df-ed789fb6dbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "path = 'full_network.pth'\n",
        "\n",
        "# save the model\n",
        "torch.save(network, path)\n",
        "\n",
        "# load the model\n",
        "new_model = torch.load(path)\n",
        "new_model.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Network. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2Ap96nyj4D",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqd8k1-ghIXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4275580b-14ec-4e7f-e475-5020f18c1741"
      },
      "source": [
        "test_model(new_model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of test images: 10000\n",
            "Total number of correct predictions: 7884\n",
            "Accuracy: 78.83999824523926\n",
            "Elapsed Time : 0.8697969913482666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}