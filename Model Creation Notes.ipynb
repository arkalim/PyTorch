{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model Creation Notes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"u3BXcOoAr9Ci","colab_type":"text"},"source":["Today, we are going to see how to use the three main building blocks of PyTorch: Module, Sequential and ModuleList. We are going to start with an example and iteratively we will make it better."]},{"cell_type":"code","metadata":{"id":"LN2kJwQOqFXm","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nhoWh6masgqP","colab_type":"text"},"source":["## Simplest version of a classifier model"]},{"cell_type":"code","metadata":{"id":"gjSpw4ujsKCV","colab_type":"code","outputId":"a900cabf-e608-45b0-c91f-213be3fbc950","executionInfo":{"status":"ok","timestamp":1561271471753,"user_tz":-330,"elapsed":2225,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["class Network(nn.Module):\n","    def __init__(self, in_c, n_classes):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_c, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        \n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","\n","        self.fc1 = nn.Linear(32 * 28 * 28, 1024)\n","        self.fc2 = nn.Linear(1024, n_classes)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        \n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","\n","        x = x.view(x.size(0), -1) # flat\n","        \n","        x = self.fc1(x)\n","        x = F.sigmoid(x)\n","        x = self.fc2(x)\n","        \n","        return x\n","    \n","model = Network(1,10)\n","print(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=25088, out_features=1024, bias=True)\n","  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TvxZHUrms28I","colab_type":"text"},"source":["If we want to add a layer we have to again write lots of code in the __init__ and in the forward function. Also, if we have some common block that we want to use in another model, e.g. the 3x3 conv + batchnorm + relu, we have to write it again.\n","## Sequential: stack and merge layers"]},{"cell_type":"code","metadata":{"id":"-tt59aQ-s3xr","colab_type":"code","outputId":"0a26f66a-69dd-4139-92e6-69afc635713f","executionInfo":{"status":"ok","timestamp":1561271472256,"user_tz":-330,"elapsed":2711,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["class Network(nn.Module):\n","    \n","    def __init__(self, channel_in, num_classes):\n","        super().__init__()\n","        \n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(channel_in, 32, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU()\n","        )\n","        \n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU()\n","        )\n","        \n","        self.decoder = nn.Sequential(\n","            nn.Linear(32 * 28 * 28, 1024),\n","            nn.Sigmoid(),\n","            nn.Linear(1024, num_classes)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","\n","        x = x.view(x.size(dim = 0), -1) # flatten\n","        \n","        x = self.decoder(x)\n","        \n","        return x\n","    \n","model = Network(1,10) \n","print(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (conv_block1): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv_block2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): Sigmoid()\n","    (2): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EY1XTcC_uDTC","colab_type":"text"},"source":["Still, conv_block1 and conv_block2 looks almost the same. We could create a function that reteurns a nn.Sequential to even simplify the code!"]},{"cell_type":"code","metadata":{"id":"W9Ohb_nTu3aX","colab_type":"code","outputId":"e6ecd3c0-9e4b-43b5-e437-45debf56fc9c","executionInfo":{"status":"ok","timestamp":1561271472745,"user_tz":-330,"elapsed":3181,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["class Network(nn.Module):\n","    def __init__(self, in_channel, num_classes):\n","        super().__init__()\n","        \n","        # defining the conv blocks as attributes\n","        self.conv_block1 = self.conv_block(in_channel, 32, kernel_size=3, padding=1)\n","        \n","        self.conv_block2 = self.conv_block(32, 64, kernel_size=3, padding=1)\n","        \n","        self.decoder = nn.Sequential(\n","            nn.Linear(32 * 28 * 28, 1024),\n","            nn.Sigmoid(),\n","            nn.Linear(1024, num_classes)\n","        )\n","        \n","    # function that returns conv blocks    \n","    def conv_block(self,in_filters, out_filters, *args, **kwargs):\n","        return nn.Sequential(\n","            nn.Conv2d(in_filters, out_filters, *args, **kwargs),\n","            nn.BatchNorm2d(out_filters),\n","            nn.ReLU()\n","        )    \n","\n","        \n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","\n","        x = x.view(x.size(0), -1) # flat\n","        \n","        x = self.decoder(x)\n","        \n","        return x\n","    \n","network_2 = Network(1,10)\n","print(network_2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (conv_block1): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv_block2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): Sigmoid()\n","    (2): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e2jEzCDLwDvF","colab_type":"text"},"source":["Still conv_block1 and conv_block2 are almost the same! We can merge them using nn.Sequential"]},{"cell_type":"code","metadata":{"id":"w_oeT3TVvh6M","colab_type":"code","outputId":"a283501b-20aa-43ef-e054-0bc2a4f0c7f0","executionInfo":{"status":"ok","timestamp":1561271472747,"user_tz":-330,"elapsed":3168,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["class Network(nn.Module):\n","    def __init__(self, in_channel, num_classes):\n","        super().__init__()\n","        \n","        # defining the encoder as a Sequential combination of conv blocks\n","        self.encoder = nn.Sequential(\n","            self.conv_block(in_channel, 32, kernel_size=3, padding=1),\n","            self.conv_block(32, 64, kernel_size=3, padding=1)\n","        )\n","        \n","        self.decoder = nn.Sequential(\n","            nn.Linear(32 * 28 * 28, 1024),\n","            nn.Sigmoid(),\n","            nn.Linear(1024, num_classes)\n","        )\n","        \n","    # function that returns conv blocks    \n","    def conv_block(self,in_filters, out_filters, *args, **kwargs):\n","        return nn.Sequential(\n","            nn.Conv2d(in_filters, out_filters, *args, **kwargs),\n","            nn.BatchNorm2d(out_filters),\n","            nn.ReLU()\n","        )    \n","\n","        \n","    def forward(self, x):\n","        x = self.encoder(x)\n","\n","        x = x.view(x.size(0), -1) # flat\n","        \n","        x = self.decoder(x)\n","        \n","        return x\n","    \n","network_3 = Network(1,10)\n","print(network_3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (encoder): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): Sigmoid()\n","    (2): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ujA9QJXqRWUm","colab_type":"text"},"source":["## ModuleList : when we need to iterate\n","ModuleList allows you to store Module as a list. It can be useful when you need to iterate through layer and store/use some information, like in U-net.\n","\n","The main difference between Sequential is that ModuleList have not a forward method so the inner layers are not connected. Assuming we need each output of each layer in the decoder, we can store it by:"]},{"cell_type":"code","metadata":{"id":"AvUHhfBsRX5k","colab_type":"code","outputId":"2d2f3620-7e90-4a72-cf23-ca913966201e","executionInfo":{"status":"ok","timestamp":1561271472748,"user_tz":-330,"elapsed":3151,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":210}},"source":["class Network(nn.Module):\n","    \n","    def __init__(self, sizes):\n","        super().__init__()\n","        # use this form to make a list of layers\n","        self.layers = nn.ModuleList([nn.Linear(filters_in, filters_out) for filters_in, filters_out in zip(sizes, sizes[1:])])\n","        self.trace = []\n","        \n","    def forward(self,x):\n","        for layer in self.layers:\n","            x = layer(x)\n","            # append the output of each layer to trace\n","            self.trace.append(x)\n","        return x\n","    \n","model = Network([1,16,32,64])    \n","\n","print(model)\n","\n","# feed a random tensor into the model to see the output of each layer\n","out = model(torch.rand((4,1)))\n","\n","[print(x.shape) for x in model.trace]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (layers): ModuleList(\n","    (0): Linear(in_features=1, out_features=16, bias=True)\n","    (1): Linear(in_features=16, out_features=32, bias=True)\n","    (2): Linear(in_features=32, out_features=64, bias=True)\n","  )\n",")\n","torch.Size([4, 16])\n","torch.Size([4, 32])\n","torch.Size([4, 64])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[None, None, None]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Q7N48tjKU04H","colab_type":"text"},"source":["## ModuleDict: when we need to choose\n","What if we want to switch to LearkyRelu in our conv_block? We can use ModuleDict to create a dictionary of Module and dynamically switch Module when we want"]},{"cell_type":"code","metadata":{"id":"6krgJct8U2sp","colab_type":"code","outputId":"d9fb203a-035f-474f-bec5-63907742d3d2","executionInfo":{"status":"ok","timestamp":1561271472749,"user_tz":-330,"elapsed":3137,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["def conv_block(in_f, out_f, activation='relu', *args, **kwargs):\n","    \n","    activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU()],\n","                ['relu', nn.ReLU()]\n","    ])\n","    \n","    return nn.Sequential(\n","        nn.Conv2d(in_f, out_f, *args, **kwargs),\n","        nn.BatchNorm2d(out_f),\n","        activations[activation]\n","    )\n","\n","print(conv_block(1, 32,'lrelu', kernel_size=3, padding=1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): LeakyReLU(negative_slope=0.01)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WN0xAkToV1uZ","colab_type":"text"},"source":["## Accessing weights of model"]},{"cell_type":"code","metadata":{"id":"XpcDIhM_YXZb","colab_type":"code","outputId":"d648f9c6-aaef-4d0e-bcc6-6704ecbc4ac9","executionInfo":{"status":"ok","timestamp":1561271472750,"user_tz":-330,"elapsed":3122,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["for name, param in network_2.named_parameters():\n","    print('Name: {}      Shape: {}'.format(name, param.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Name: conv_block1.0.weight      Shape: torch.Size([32, 1, 3, 3])\n","Name: conv_block1.0.bias      Shape: torch.Size([32])\n","Name: conv_block1.1.weight      Shape: torch.Size([32])\n","Name: conv_block1.1.bias      Shape: torch.Size([32])\n","Name: conv_block2.0.weight      Shape: torch.Size([64, 32, 3, 3])\n","Name: conv_block2.0.bias      Shape: torch.Size([64])\n","Name: conv_block2.1.weight      Shape: torch.Size([64])\n","Name: conv_block2.1.bias      Shape: torch.Size([64])\n","Name: decoder.0.weight      Shape: torch.Size([1024, 25088])\n","Name: decoder.0.bias      Shape: torch.Size([1024])\n","Name: decoder.2.weight      Shape: torch.Size([10, 1024])\n","Name: decoder.2.bias      Shape: torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tee1xM9XYaWR","colab_type":"code","outputId":"e3fb450e-4ad4-4aef-ac9f-4150b3aa7f4b","executionInfo":{"status":"ok","timestamp":1561271472750,"user_tz":-330,"elapsed":3104,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":2815}},"source":["print(network_2.conv_block1[0].weight)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([[[[-0.0968, -0.0176,  0.2056],\n","          [ 0.2380, -0.2025, -0.0140],\n","          [ 0.0016, -0.2793, -0.2413]]],\n","\n","\n","        [[[-0.0581,  0.1973, -0.1767],\n","          [ 0.1951, -0.2000, -0.1600],\n","          [ 0.1384,  0.0581, -0.0950]]],\n","\n","\n","        [[[ 0.2822, -0.0789,  0.0566],\n","          [-0.3128,  0.1762, -0.0464],\n","          [ 0.2763, -0.2105, -0.0805]]],\n","\n","\n","        [[[-0.0070,  0.2555, -0.1148],\n","          [ 0.1730, -0.2041,  0.2247],\n","          [ 0.2175,  0.0277,  0.1433]]],\n","\n","\n","        [[[ 0.0004,  0.2964, -0.3164],\n","          [ 0.2352,  0.2817,  0.2959],\n","          [-0.2600, -0.2384, -0.2324]]],\n","\n","\n","        [[[-0.1866, -0.0754,  0.2645],\n","          [-0.3185, -0.0444, -0.2537],\n","          [-0.0934, -0.1955,  0.1101]]],\n","\n","\n","        [[[ 0.2920,  0.0449, -0.2449],\n","          [ 0.2203,  0.1899, -0.2187],\n","          [ 0.0010, -0.1576,  0.2997]]],\n","\n","\n","        [[[-0.1905,  0.3149, -0.2065],\n","          [-0.0053, -0.1043, -0.0436],\n","          [ 0.2638, -0.2825, -0.2655]]],\n","\n","\n","        [[[-0.2646,  0.0778,  0.1612],\n","          [-0.0161, -0.2744, -0.2687],\n","          [ 0.0292, -0.3091,  0.1500]]],\n","\n","\n","        [[[ 0.1330, -0.0557, -0.1866],\n","          [-0.0054,  0.1707,  0.0301],\n","          [-0.2403,  0.0263, -0.3241]]],\n","\n","\n","        [[[-0.1133,  0.0159,  0.3092],\n","          [-0.3250, -0.0379,  0.1551],\n","          [-0.1684,  0.0945, -0.3080]]],\n","\n","\n","        [[[-0.1460, -0.0650,  0.2053],\n","          [ 0.2920,  0.2083, -0.1366],\n","          [-0.0795, -0.0505, -0.0400]]],\n","\n","\n","        [[[ 0.3188, -0.2484,  0.3243],\n","          [-0.1040, -0.1101,  0.2256],\n","          [ 0.2192, -0.2436,  0.0692]]],\n","\n","\n","        [[[ 0.0872, -0.3125,  0.0357],\n","          [ 0.1546,  0.0531, -0.2463],\n","          [ 0.1085,  0.1913, -0.0232]]],\n","\n","\n","        [[[ 0.2473,  0.1692,  0.0113],\n","          [ 0.2118, -0.2139, -0.2361],\n","          [ 0.1121,  0.1174, -0.0637]]],\n","\n","\n","        [[[ 0.2855, -0.0587, -0.0968],\n","          [-0.2541,  0.2415, -0.2541],\n","          [-0.1806,  0.0628,  0.1367]]],\n","\n","\n","        [[[ 0.0736,  0.2672, -0.1754],\n","          [-0.0381,  0.2678, -0.2456],\n","          [-0.2654, -0.0485, -0.0172]]],\n","\n","\n","        [[[-0.1369,  0.0513, -0.1383],\n","          [ 0.1178, -0.1233,  0.1069],\n","          [-0.0893, -0.0271,  0.3080]]],\n","\n","\n","        [[[ 0.2509,  0.0774, -0.1013],\n","          [ 0.2381,  0.1646, -0.3008],\n","          [-0.0414,  0.1778,  0.2911]]],\n","\n","\n","        [[[ 0.1983,  0.2857, -0.3000],\n","          [-0.2457, -0.3247,  0.3161],\n","          [-0.1400, -0.1440,  0.2229]]],\n","\n","\n","        [[[ 0.1901, -0.2259,  0.2004],\n","          [-0.2802, -0.1218, -0.2970],\n","          [-0.3286,  0.1715, -0.0136]]],\n","\n","\n","        [[[ 0.0278,  0.0711,  0.2462],\n","          [ 0.1207,  0.0268, -0.3129],\n","          [ 0.0479, -0.0045,  0.1511]]],\n","\n","\n","        [[[ 0.0041, -0.2306,  0.0958],\n","          [ 0.2269,  0.0783, -0.1297],\n","          [-0.1357,  0.1339,  0.1257]]],\n","\n","\n","        [[[-0.1349, -0.1059,  0.1187],\n","          [-0.0119,  0.1374, -0.0898],\n","          [ 0.3256,  0.0444, -0.1162]]],\n","\n","\n","        [[[ 0.1576, -0.2551,  0.2275],\n","          [ 0.2940, -0.1235,  0.3270],\n","          [ 0.0668, -0.2934, -0.0038]]],\n","\n","\n","        [[[ 0.3085,  0.2770,  0.0791],\n","          [-0.0510, -0.1650,  0.2464],\n","          [-0.2658, -0.0273,  0.0895]]],\n","\n","\n","        [[[-0.1607, -0.0934, -0.0464],\n","          [ 0.1701, -0.3251,  0.2858],\n","          [ 0.3045,  0.2244,  0.3120]]],\n","\n","\n","        [[[-0.2866, -0.3140, -0.2055],\n","          [ 0.1846, -0.0189,  0.3146],\n","          [-0.2833, -0.1737,  0.2724]]],\n","\n","\n","        [[[ 0.1766,  0.2645,  0.1891],\n","          [ 0.2238, -0.2266, -0.2343],\n","          [ 0.2017,  0.2763,  0.1804]]],\n","\n","\n","        [[[-0.1168,  0.2595,  0.1779],\n","          [ 0.2367, -0.2878,  0.3214],\n","          [ 0.1647, -0.3255, -0.0175]]],\n","\n","\n","        [[[-0.3249, -0.2203, -0.2552],\n","          [-0.1623, -0.0280, -0.1256],\n","          [-0.0991,  0.2603, -0.2055]]],\n","\n","\n","        [[[-0.2824,  0.2624, -0.1074],\n","          [ 0.0316, -0.3190, -0.1309],\n","          [ 0.1565,  0.1987,  0.2512]]]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RmHZnylNV49E","colab_type":"code","outputId":"46f70d5a-1017-42bd-f3e4-62984c8c895b","executionInfo":{"status":"ok","timestamp":1561271472751,"user_tz":-330,"elapsed":3086,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["for name, param in network_3.named_parameters():\n","    print('Name: {}      Shape: {}'.format(name, param.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Name: encoder.0.0.weight      Shape: torch.Size([32, 1, 3, 3])\n","Name: encoder.0.0.bias      Shape: torch.Size([32])\n","Name: encoder.0.1.weight      Shape: torch.Size([32])\n","Name: encoder.0.1.bias      Shape: torch.Size([32])\n","Name: encoder.1.0.weight      Shape: torch.Size([64, 32, 3, 3])\n","Name: encoder.1.0.bias      Shape: torch.Size([64])\n","Name: encoder.1.1.weight      Shape: torch.Size([64])\n","Name: encoder.1.1.bias      Shape: torch.Size([64])\n","Name: decoder.0.weight      Shape: torch.Size([1024, 25088])\n","Name: decoder.0.bias      Shape: torch.Size([1024])\n","Name: decoder.2.weight      Shape: torch.Size([10, 1024])\n","Name: decoder.2.bias      Shape: torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nNElPGpKXLpE","colab_type":"code","outputId":"3163a94b-735a-4816-8ce2-48bf1a925c1c","executionInfo":{"status":"ok","timestamp":1561271472752,"user_tz":-330,"elapsed":3070,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":2815}},"source":["print(network_3.encoder[0][0].weight)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([[[[-0.1010, -0.0993,  0.0706],\n","          [ 0.0888,  0.3237,  0.3193],\n","          [ 0.3108,  0.0830, -0.3037]]],\n","\n","\n","        [[[ 0.2009,  0.1916, -0.2025],\n","          [ 0.3180,  0.2431, -0.0588],\n","          [-0.3331, -0.2871,  0.2003]]],\n","\n","\n","        [[[ 0.3035,  0.1326, -0.2049],\n","          [ 0.1352,  0.1921, -0.0957],\n","          [ 0.1206, -0.0506,  0.2487]]],\n","\n","\n","        [[[-0.2404,  0.2763, -0.0284],\n","          [ 0.2143,  0.2812,  0.1206],\n","          [-0.1870, -0.2508,  0.2792]]],\n","\n","\n","        [[[ 0.1795,  0.0486,  0.2426],\n","          [-0.2224, -0.0175, -0.0583],\n","          [ 0.1608, -0.2588,  0.2775]]],\n","\n","\n","        [[[-0.2269, -0.1922,  0.3026],\n","          [ 0.0338, -0.0343,  0.0176],\n","          [-0.2817,  0.2951, -0.0739]]],\n","\n","\n","        [[[-0.1770, -0.0691, -0.3088],\n","          [-0.0548,  0.1882,  0.0971],\n","          [ 0.2351,  0.1257, -0.1398]]],\n","\n","\n","        [[[-0.0038,  0.0858, -0.0782],\n","          [ 0.2513, -0.2480,  0.2173],\n","          [ 0.2378, -0.2329, -0.0094]]],\n","\n","\n","        [[[-0.3147,  0.3039,  0.1416],\n","          [ 0.0523, -0.1305, -0.0935],\n","          [ 0.0391,  0.0990, -0.3235]]],\n","\n","\n","        [[[ 0.2015, -0.1229, -0.1689],\n","          [-0.0314, -0.1599, -0.2099],\n","          [-0.2764,  0.0662, -0.2265]]],\n","\n","\n","        [[[ 0.1013,  0.1409, -0.2799],\n","          [-0.2818, -0.0264,  0.2448],\n","          [-0.2685,  0.2506,  0.0217]]],\n","\n","\n","        [[[-0.0662, -0.0619,  0.2809],\n","          [-0.2479, -0.0910, -0.2421],\n","          [-0.2599,  0.2744,  0.1939]]],\n","\n","\n","        [[[ 0.2880, -0.3279,  0.0149],\n","          [-0.2220,  0.2567, -0.0623],\n","          [-0.1322,  0.1548, -0.3200]]],\n","\n","\n","        [[[ 0.0730,  0.2685, -0.0891],\n","          [ 0.1022, -0.2226,  0.1211],\n","          [-0.3054, -0.1250,  0.0874]]],\n","\n","\n","        [[[ 0.0407, -0.0566,  0.2453],\n","          [-0.2551,  0.0619, -0.3213],\n","          [ 0.1913, -0.3291,  0.2274]]],\n","\n","\n","        [[[-0.1100,  0.1103,  0.2335],\n","          [-0.3126,  0.0155,  0.1182],\n","          [ 0.2325,  0.0067,  0.3193]]],\n","\n","\n","        [[[ 0.0669,  0.3134, -0.0457],\n","          [ 0.2062, -0.1787, -0.0659],\n","          [-0.0900,  0.1110,  0.1373]]],\n","\n","\n","        [[[-0.1400, -0.0652, -0.1122],\n","          [-0.2263,  0.2941, -0.2497],\n","          [ 0.0764,  0.2013, -0.2518]]],\n","\n","\n","        [[[ 0.0855,  0.0508, -0.1855],\n","          [-0.2611, -0.1931,  0.1081],\n","          [-0.0699,  0.3104, -0.0376]]],\n","\n","\n","        [[[ 0.3296,  0.2740, -0.3099],\n","          [ 0.1278, -0.1706,  0.1871],\n","          [ 0.0124, -0.2421, -0.0585]]],\n","\n","\n","        [[[ 0.1115,  0.2875, -0.0423],\n","          [-0.1394, -0.1540,  0.1921],\n","          [ 0.2828,  0.2277, -0.1977]]],\n","\n","\n","        [[[-0.3310, -0.2299,  0.3203],\n","          [ 0.1369, -0.0717,  0.1063],\n","          [-0.3296, -0.1180, -0.2283]]],\n","\n","\n","        [[[-0.2310, -0.2601, -0.1026],\n","          [ 0.1121, -0.1817, -0.2455],\n","          [-0.3237, -0.0355,  0.0300]]],\n","\n","\n","        [[[ 0.3083,  0.0335, -0.0378],\n","          [-0.3004, -0.2396,  0.1061],\n","          [-0.2287,  0.0976, -0.0450]]],\n","\n","\n","        [[[-0.3311, -0.1300,  0.0477],\n","          [ 0.0456,  0.0694, -0.1494],\n","          [ 0.2207, -0.2863, -0.0147]]],\n","\n","\n","        [[[-0.0511,  0.0482,  0.2346],\n","          [ 0.0274,  0.1551,  0.0366],\n","          [ 0.0605, -0.0550,  0.0860]]],\n","\n","\n","        [[[-0.1493,  0.1503, -0.1809],\n","          [ 0.0921, -0.0966,  0.0926],\n","          [ 0.3138,  0.1837, -0.1966]]],\n","\n","\n","        [[[-0.2896, -0.2595,  0.0555],\n","          [ 0.1209, -0.1642,  0.2983],\n","          [-0.3323,  0.0562,  0.0523]]],\n","\n","\n","        [[[ 0.0387, -0.1896,  0.0054],\n","          [-0.0617,  0.1240, -0.1092],\n","          [-0.1353,  0.0169, -0.0788]]],\n","\n","\n","        [[[ 0.2485, -0.1138,  0.1413],\n","          [ 0.2475, -0.0482, -0.0228],\n","          [ 0.1885, -0.3049,  0.0114]]],\n","\n","\n","        [[[ 0.1716,  0.0684, -0.2727],\n","          [-0.1975,  0.2369,  0.1533],\n","          [ 0.0284,  0.0726, -0.3197]]],\n","\n","\n","        [[[-0.1051, -0.0449, -0.0216],\n","          [-0.1287, -0.0985,  0.2589],\n","          [-0.2654,  0.1058, -0.0487]]]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tl1UhJzMZ3j_","colab_type":"text"},"source":["## Accessing weights of a specific block or layer"]},{"cell_type":"markdown","metadata":{"id":"i6rL2odnZ1yG","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"EXxGylnGZSh0","colab_type":"code","outputId":"f126c6a2-5d61-472c-d407-c700b664f3bc","executionInfo":{"status":"ok","timestamp":1561271472753,"user_tz":-330,"elapsed":3057,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["for name, param in network_3.encoder.named_parameters():\n","    print('Name: {}      Shape: {}'.format(name, param.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Name: 0.0.weight      Shape: torch.Size([32, 1, 3, 3])\n","Name: 0.0.bias      Shape: torch.Size([32])\n","Name: 0.1.weight      Shape: torch.Size([32])\n","Name: 0.1.bias      Shape: torch.Size([32])\n","Name: 1.0.weight      Shape: torch.Size([64, 32, 3, 3])\n","Name: 1.0.bias      Shape: torch.Size([64])\n","Name: 1.1.weight      Shape: torch.Size([64])\n","Name: 1.1.bias      Shape: torch.Size([64])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ek57yRhBcAus","colab_type":"text"},"source":["## Adding layers to the model"]},{"cell_type":"code","metadata":{"id":"crMD-7xrcASG","colab_type":"code","outputId":"f05000a9-c021-4e6c-d7e6-fef7c5cfa0c1","executionInfo":{"status":"ok","timestamp":1561271472753,"user_tz":-330,"elapsed":3039,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":369}},"source":["# adding a layer named 'new_layer' to encoder[0] block\n","network_3.encoder[0].new_layer = nn.Linear(12,13)\n","\n","print(network_3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Network(\n","  (encoder): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (new_layer): Linear(in_features=12, out_features=13, bias=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): Sigmoid()\n","    (2): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f-5lST8HiQQt","colab_type":"text"},"source":["## Unfreezing selected layers"]},{"cell_type":"code","metadata":{"id":"ZTC-IUFsiSne","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.fc1 = nn.Linear(1, 16)\n","        self.fc2 = nn.Linear(16, 8)\n","        self.fc3 = nn.Linear(8, 4)\n","        self.fc4 = nn.Linear(4, 2)\n","        self.fc5 = nn.Linear(2, 1)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        x = self.fc4(x)\n","        x = self.fc5(x)\n","        return x\n","\n","net = Net()    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EpghJz6xkefn","colab_type":"text"},"source":["### Find different components of the model\n"]},{"cell_type":"code","metadata":{"id":"DjwqHxgVjcQx","colab_type":"code","outputId":"58360f1f-6511-46ae-f205-2183df939b72","executionInfo":{"status":"ok","timestamp":1561271472757,"user_tz":-330,"elapsed":3017,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["for name, child in net.named_children():\n","    print(name)  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["fc1\n","fc2\n","fc3\n","fc4\n","fc5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-p6pDyQYkbL-","colab_type":"text"},"source":["### Freeze selected layers"]},{"cell_type":"code","metadata":{"id":"3wfX-hDkkA99","colab_type":"code","outputId":"6be4924e-2b51-4233-a418-ec5535b61867","executionInfo":{"status":"ok","timestamp":1561271472757,"user_tz":-330,"elapsed":3002,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["for name, child in net.named_children():\n","    \n","    if name in ['fc4', 'fc5']:\n","        print(name + ' is unfrozen')\n","        for param in child.parameters():\n","            param.requires_grad = True\n","    else:\n","        print(name + ' is frozen')\n","        for param in child.parameters():\n","            param.requires_grad = False"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fc1 is frozen\n","fc2 is frozen\n","fc3 is frozen\n","fc4 is unfrozen\n","fc5 is unfrozen\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DRSR6WXynZH8","colab_type":"text"},"source":["# Different ways to define Sequential Models"]},{"cell_type":"code","metadata":{"id":"P0EEuwPGnYcw","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DH15MhebnyBk","colab_type":"text"},"source":["### Method 1: Without mentioning layer names"]},{"cell_type":"code","metadata":{"id":"QfzYZHQYnw6E","colab_type":"code","outputId":"e40e80e9-0d08-4513-e50c-d14c42205fae","executionInfo":{"status":"ok","timestamp":1561271472761,"user_tz":-330,"elapsed":2982,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["model_Seq1 = nn.Sequential(\n","          nn.Conv2d(1,20,5),\n","          nn.ReLU(),\n","          nn.Conv2d(20,64,5),\n","          nn.ReLU()\n","        )\n","\n","print(model_Seq1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (3): ReLU()\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s4NH1_NXoB8q","colab_type":"text"},"source":["Layers are numbered sequentially by default\n","### Method 2: Mention layer names  using OrderedDict"]},{"cell_type":"code","metadata":{"id":"PiePCkwFoEjd","colab_type":"code","outputId":"e1f6d1e9-3b60-498e-d07e-357397829fb4","executionInfo":{"status":"ok","timestamp":1561271472762,"user_tz":-330,"elapsed":2970,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# An OrderedDict is a dictionary subclass that remembers the order that keys were first inserted. \n","# The only difference between dict() and OrderedDict() is that:\n","\n","# OrderedDict preserves the order in which the keys are inserted. \n","# A regular dict doesn’t track the insertion order, \n","# and iterating it gives the values in an arbitrary order. \n","# By contrast, the order the items are inserted is remembered by OrderedDict.\n","\n","model_Seq2 = nn.Sequential(OrderedDict([\n","          ('conv1', nn.Conv2d(1,20,5)),\n","          ('relu1', nn.ReLU()),\n","          ('conv2', nn.Conv2d(20,64,5)),\n","          ('relu2', nn.ReLU())\n","        ]))\n","\n","print(model_Seq2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (relu1): ReLU()\n","  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (relu2): ReLU()\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lmO7Fqyvop8S","colab_type":"text"},"source":["### Method 3: Using a list of layers"]},{"cell_type":"code","metadata":{"id":"UkW-e2COopn9","colab_type":"code","outputId":"71cf4eb9-9f9d-49f7-f6a0-a9138a9ddd12","executionInfo":{"status":"ok","timestamp":1561271472763,"user_tz":-330,"elapsed":2956,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["layers = []\n","layers.append(nn.Linear(3, 4))\n","layers.append(nn.Sigmoid())\n","layers.append(nn.Linear(4, 1))\n","layers.append(nn.Sigmoid())\n","\n","model_Seq3 = nn.Sequential(*layers)\n","\n","print(model_Seq3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=3, out_features=4, bias=True)\n","  (1): Sigmoid()\n","  (2): Linear(in_features=4, out_features=1, bias=True)\n","  (3): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i9zqXk8Yp2-X","colab_type":"text"},"source":["In this case also, layers are numbered by default\n","### Method 4: Using class"]},{"cell_type":"code","metadata":{"id":"D4eIfTJnp7WF","colab_type":"code","outputId":"47e9ad5d-ad9f-4cda-e584-c5b242dcff57","executionInfo":{"status":"ok","timestamp":1561271473182,"user_tz":-330,"elapsed":3359,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["class ConvNet(torch.nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","\n","        self.conv = torch.nn.Sequential()\n","        self.conv.add_module(\"conv_1\", torch.nn.Conv2d(1, 10, kernel_size=5))\n","        self.conv.add_module(\"maxpool_1\", torch.nn.MaxPool2d(kernel_size=2))\n","        self.conv.add_module(\"relu_1\", torch.nn.ReLU())\n","        self.conv.add_module(\"conv_2\", torch.nn.Conv2d(10, 20, kernel_size=5))\n","        self.conv.add_module(\"dropout_2\", torch.nn.Dropout(p=0.2))\n","        \n","model_Seq4 = ConvNet()\n","\n","print(model_Seq4)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ConvNet(\n","  (conv): Sequential(\n","    (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n","    (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (relu_1): ReLU()\n","    (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n","    (dropout_2): Dropout(p=0.2)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"39UKd25UrOQm","colab_type":"text"},"source":["## Adding, Accessing and Replacing layers in Sequential Models"]},{"cell_type":"code","metadata":{"id":"uP6nnT5trViF","colab_type":"code","outputId":"92aa451e-9a0c-47bf-aeb0-f7809a702bc4","executionInfo":{"status":"ok","timestamp":1561271473183,"user_tz":-330,"elapsed":3343,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Accessing the layers\n","print(model_Seq1[0])\n","print(model_Seq2.conv1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"elsU6j1nsUsB","colab_type":"code","outputId":"93e92dfa-603c-482f-b287-098a5e655645","executionInfo":{"status":"ok","timestamp":1561271473183,"user_tz":-330,"elapsed":3328,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["# replacing the layers\n","model_Seq1[0] = nn.Conv2d(1,50,7,2)\n","model_Seq2.conv1 = nn.Conv2d(1,50,7,2)\n","\n","print(model_Seq1)\n","print(model_Seq2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n","  (1): ReLU()\n","  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (3): ReLU()\n",")\n","Sequential(\n","  (conv1): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n","  (relu1): ReLU()\n","  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (relu2): ReLU()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"seOpbfsZsZfw","colab_type":"code","outputId":"674d5e45-a148-4b87-f4f8-0bd91e9a855b","executionInfo":{"status":"ok","timestamp":1561271473184,"user_tz":-330,"elapsed":3316,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["# Adding layers\n","model_Seq1 = nn.Sequential(model_Seq1, torch.nn.Linear(2048,365))\n","model_Seq2.add_module('conv3', nn.Conv2d(64, 64, 5))\n","\n","print(model_Seq1)\n","print(model_Seq2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n","    (1): ReLU()\n","    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","    (3): ReLU()\n","  )\n","  (1): Linear(in_features=2048, out_features=365, bias=True)\n",")\n","Sequential(\n","  (conv1): Conv2d(1, 50, kernel_size=(7, 7), stride=(2, 2))\n","  (relu1): ReLU()\n","  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (relu2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tSog068Rs6eS","colab_type":"text"},"source":["## Adding layers to a pretrained model"]},{"cell_type":"code","metadata":{"id":"1-xbfX8js8Sb","colab_type":"code","outputId":"ddf13d12-6eec-4424-80b7-5df87f64ddda","executionInfo":{"status":"ok","timestamp":1561271481451,"user_tz":-330,"elapsed":11569,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":2853}},"source":["# Pretrained Model\n","vgg = models.vgg16(pretrained = True)\n","print(\"Pretrained Model\")\n","print(vgg)\n","\n","# Adding on top of the model\n","print(\"\\n Adding on top of the model\")\n","on_top = nn.Sequential(vgg, net)\n","print(on_top)\n","\n","# take care of the shapes when adding inbetween\n","print(\"\\n Adding in between the model\")\n","in_between = nn.Sequential(vgg.features[:5] , net , vgg.features[5:] , vgg.avgpool , vgg.classifier)\n","print(in_between)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n","100%|██████████| 553433881/553433881 [00:06<00:00, 88062725.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Pretrained Model\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n","\n"," Adding on top of the model\n","Sequential(\n","  (0): VGG(\n","    (features): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace)\n","      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (6): ReLU(inplace)\n","      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): ReLU(inplace)\n","      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): ReLU(inplace)\n","      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (13): ReLU(inplace)\n","      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (15): ReLU(inplace)\n","      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (18): ReLU(inplace)\n","      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (20): ReLU(inplace)\n","      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (22): ReLU(inplace)\n","      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (25): ReLU(inplace)\n","      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (27): ReLU(inplace)\n","      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (29): ReLU(inplace)\n","      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    (classifier): Sequential(\n","      (0): Linear(in_features=25088, out_features=4096, bias=True)\n","      (1): ReLU(inplace)\n","      (2): Dropout(p=0.5)\n","      (3): Linear(in_features=4096, out_features=4096, bias=True)\n","      (4): ReLU(inplace)\n","      (5): Dropout(p=0.5)\n","      (6): Linear(in_features=4096, out_features=1000, bias=True)\n","    )\n","  )\n","  (1): Net(\n","    (fc1): Linear(in_features=1, out_features=16, bias=True)\n","    (fc2): Linear(in_features=16, out_features=8, bias=True)\n","    (fc3): Linear(in_features=8, out_features=4, bias=True)\n","    (fc4): Linear(in_features=4, out_features=2, bias=True)\n","    (fc5): Linear(in_features=2, out_features=1, bias=True)\n","  )\n",")\n","\n"," Adding in between the model\n","Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Net(\n","    (fc1): Linear(in_features=1, out_features=16, bias=True)\n","    (fc2): Linear(in_features=16, out_features=8, bias=True)\n","    (fc3): Linear(in_features=8, out_features=4, bias=True)\n","    (fc4): Linear(in_features=4, out_features=2, bias=True)\n","    (fc5): Linear(in_features=2, out_features=1, bias=True)\n","  )\n","  (2): Sequential(\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (3): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (4): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vdXeAg8n189V","colab_type":"text"},"source":["# Replacing layers of a pretrained network"]},{"cell_type":"code","metadata":{"id":"o9AyTylT198n","colab_type":"code","colab":{}},"source":["vgg16 = models.vgg16(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vD6RxGNZ5Knc","colab_type":"code","outputId":"304faef8-e9b6-4bc2-f95c-723510a9ed35","executionInfo":{"status":"ok","timestamp":1561271483561,"user_tz":-330,"elapsed":13645,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# select a particular layer to replace\n","layers = list(vgg16.children())\n","print('Last Layer',layers[2][-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Last Layer Linear(in_features=4096, out_features=1000, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZkPTVaI35Hxw","colab_type":"code","outputId":"59c7f309-2560-4a23-8e8c-b1833445ea29","executionInfo":{"status":"ok","timestamp":1561271483562,"user_tz":-330,"elapsed":13629,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":879}},"source":["# replace the selected layer\n","layers[2][-1] = nn.Linear(4096, 10, bias = True)\n","\n","# create a new model using the list\n","new_model = nn.Sequential(*layers)\n","\n","# freeze the pretrained model \n","# Parameters of newly constructed modules have requires_grad=True by default\n","for param in new_model.parameters():\n","    param.requires_grad = False\n","    \n","# unfreeze the last layer    \n","for param in new_model[2][-1].parameters():\n","    param.requires_grad = True\n","    \n","print(new_model)    \n","\n","# print trainable parameters\n","print('Trainable Parameters: \\n')\n","for name, param in new_model.named_parameters():\n","    if param.requires_grad:\n","        print (name, param.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (2): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Trainable Parameters: \n","\n","2.6.weight torch.Size([10, 4096])\n","2.6.bias torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lleky9sZ9Pgk","colab_type":"code","outputId":"fca324d1-6fd8-4fe0-8c80-7d2d34eff21f","executionInfo":{"status":"ok","timestamp":1561271485163,"user_tz":-330,"elapsed":15213,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":879}},"source":["# Another method\n","\n","model = models.vgg16(True)\n","\n","new_model = torch.nn.Sequential(*(list(model.children())))\n","new_model[2][-1] = nn.Linear(4096, 10, bias = True)\n","\n","# freeze the pretrained model \n","# Parameters of newly constructed modules have requires_grad=True by default\n","for param in new_model.parameters():\n","    param.requires_grad = False\n","    \n","# unfreeze the last layer    \n","for param in new_model[2][-1].parameters():\n","    param.requires_grad = True\n","    \n","print(new_model)    \n","\n","# print trainable parameters\n","print('Trainable Parameters: \\n')\n","for name, param in new_model.named_parameters():\n","    if param.requires_grad:\n","        print (name, param.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (2): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","Trainable Parameters: \n","\n","2.6.weight torch.Size([10, 4096])\n","2.6.bias torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5nYsCAuiBfBA","colab_type":"text"},"source":["## Adding Layers to a pretrained network in a Class"]},{"cell_type":"code","metadata":{"id":"6FiJepzNBdyf","colab_type":"code","outputId":"fac00734-f179-4e99-db18-6b896eba07e0","executionInfo":{"status":"ok","timestamp":1561271485164,"user_tz":-330,"elapsed":15212,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        \n","        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        \n","        x = x.view(-1, 16 * 4 * 4)\n","        \n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = Net()\n","\n","print(net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=256, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4U6HJBNAB8Tj","colab_type":"code","outputId":"c4062bc1-2078-45b5-9aa7-a9b27d732568","executionInfo":{"status":"ok","timestamp":1561271664381,"user_tz":-330,"elapsed":930,"user":{"displayName":"Abdur Rahman","photoUrl":"","userId":"05342928391784981660"}},"colab":{"base_uri":"https://localhost:8080/","height":210}},"source":["# Expanding the network\n","class ExpandedNet(nn.Module):\n","    \n","    def __init__(self):\n","        super(ExpandedNet , self).__init__()\n","        self.net = Net()\n","        self.fc4 = nn.Linear(10,1)\n","        \n","    def forward(self , x):\n","        # feed the output of last layer of self.net to relu and then to fc4\n","        x = F.relu(self.net.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","    \n","new_net = ExpandedNet()\n","\n","print(new_net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ExpandedNet(\n","  (net): Net(\n","    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (fc1): Linear(in_features=256, out_features=120, bias=True)\n","    (fc2): Linear(in_features=120, out_features=84, bias=True)\n","    (fc3): Linear(in_features=84, out_features=10, bias=True)\n","  )\n","  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k95gFdsOIQJp","colab_type":"text"},"source":["## Manipulating a pretrained model\n","Sometimes it is needed to extract some features from different layers of a pretrained model in a way that forward function can be run one time. In other words, running forward function in pretrained model and stopping it in a layer whose output is our interest is not a good method. Assume you wants to get output of several layers and you must run forward function several times (ie the number of runs is the number of layers whose output is our interest). To achieve this goal it is needed some background information.\n","\n"," Assume that I want to extract the first layers of VGG16 as features. In this regard, look at the following picture. The blue line shows which outputs I consider to get from layers.\n"," \n"," ![alt text](https://user-images.githubusercontent.com/15813546/32988686-5119820c-cd1e-11e7-8213-7a21a3227863.png)\n","\n","As it can be seen from above picture and python output, our desire part of vgg net is lines in the python output correspond with line from (0) to (15). Also, we need to concatenate output of lines (3), (8) and (15). The outputs of lines (8) and (15) must be enlarged (upsample) to obtain the size of the output in line (3); then they are concatenated to acheive the result."]},{"cell_type":"code","metadata":{"id":"jwfKunr9IQju","colab_type":"code","colab":{}},"source":["from torchvision import models\n","import torch\n","import torchvision\n","import torch.nn as nn\n","\n","vgg = models.vgg16(True)\n","print(vgg)\n","\n","class myModel(nn.Module):\n","    def __init__(self):\n","        super(myModel,self).__init__()\n","        vgg_model = models.vgg16(pretrained=True)\t\n","        \n","        self.Conv1 = nn.Sequential(*list(vgg_model.children())[0][0:4])\n","        self.Conv2 = nn.Sequential(*list(vgg_model.children())[0][4:9]) \n","        self.Conv3 = nn.Sequential(*list(vgg_model.children())[0][9:16])\n","        \n","        # upsampling layers\n","        self.upSample1 = nn.Upsample(scale_factor=2)\n","        self.upSample2 = nn.Upsample(scale_factor=4)\n","\n","    def forward(self,x):\n","        out1 = self.Conv1(x)\n","        out2 = self.Conv2(out1)\n","        out3 = self.Conv3(out2)\n","        \n","        # upsampling fo skip connections\n","        out2 = self.upSample1(out2)\n","        out3 = self.upSample2(out3)\n","        \n","        # concatenate\n","        concat_features = torch.cat([out1, out2, out3], 1)\n","        return out1, concat_features"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0cMEUTr4MeMY","colab_type":"text"},"source":["In the above implementation,\n","\n","```\n","        self.Conv1 = nn.Sequential(*list(vgg_model.children())[0][0:4])\n","        self.Conv2 = nn.Sequential(*list(vgg_model.children())[0][4:9]) \n","        self.Conv3 = nn.Sequential(*list(vgg_model.children())[0][9:16])\n","```\n","can be replaced with\n","\n","\n","```\n","        self.Conv1 = nn.Sequential(*list(vgg_model.features.children())[0:4])\n","        self.Conv2 = nn.Sequential(*list(vgg_model.features.children())[4:9]) \n","        self.Conv3 = nn.Sequential(*list(vgg_model.features.children())[9:16])\n","```\n","model.features.children() gives a flattened version of model.children()\n","\n","\n"]}]}